{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bb061c2",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #002676; padding: 20px;\">\n",
    "<img src=\"https://live-masters-in-computational-social-science.pantheon.berkeley.edu/wp-content/uploads/2025/04/image-3-2.png\" alt=\"MaCSS\" width=\"200\">\n",
    "</div>\n",
    "\n",
    "# **Assignment 3:** A mini report your interactions with language models\n",
    "\n",
    "[wdtmacss@berkeley.edu](mailto:wdtmacss@berkeley.edu)\\\n",
    "**Computational Social Science 1A**\\\n",
    "[Human Psychology and Social Technologies](https://classes.berkeley.edu/content/2025-fall-compss-214a-001-lec-001) \n",
    "Fall 2025\\\n",
    "UC Berkeley [Masters in Computational Social Science](https://macss.berkeley.edu/about/)\n",
    "\n",
    "\n",
    "---\n",
    "**Table of Contents**\n",
    "\n",
    "1. [Instructions](#instructions)\n",
    "2. [Pursuasion Study](#pursuasion-study)\n",
    "3. [Available LLMs](#available-llms)\n",
    "4. [GPT2 Analysis](#gpt2-analysis)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289baeae",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "Please complete the sections below. You can edit this notebook directly. When you area ready to submit, please create a pdf of your notebook by following the instrucitons below:\n",
    "\n",
    "* Render your notebook file in a browser (just open it in your datahub and run all the cells).\n",
    "* Download the notebook at an HTML file\n",
    "* Open the HTML file in  a browser\n",
    "* Save the page as a PDF\n",
    "\n",
    "You can then upload your pdf to the Assignment 2 submission system on BCourses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda0aa7b",
   "metadata": {},
   "source": [
    "# Pursuasion Study\n",
    "In week four, we read and discussed the following research:\n",
    "\n",
    "* Salvi, F., Horta Ribeiro, M., Gallotti, R., & West, R. (2025). [On the conversational persuasiveness of GPT-4](https://www.nature.com/articles/s41562-025-02194-6). Nature Human Behaviour, 1-9.\n",
    "\n",
    "Identify at least one imoprtant limitation of the study. How could it be improved? Your answer can be relatively brief (e.g. 150 words would be fine)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec68d3f",
   "metadata": {},
   "source": [
    "> One important limitation of Salvi et al. (2025) is the artificial nature of their debate setting. The study imposed a rigid, timed debate structure with anonymized opponents, which differs substantially from how persuasion occurs in real-world environments such as social media or political discussions. Natural conversations are more fluid, often include emotional cues, identity signaling, and longer-term back-and-forth exchanges. Because participants also knew they were in an experiment and were compensated for their time, their engagement and willingness to shift opinions may not reflect organic persuasion dynamics.\n",
    "\n",
    "To improve ecological validity, future research could relax the debate format and allow for more naturalistic, open-ended interactions. Including identity cues (such as names or photos), testing in social media–like environments, and recruiting a more diverse and representative population beyond Prolific workers would help assess whether GPT-4’s persuasive advantage persists under conditions closer to everyday online discourse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c47462",
   "metadata": {},
   "source": [
    "# Available LLMs\n",
    "\n",
    "In [Notebook 5](https://github.com/ccs-ucb/CSS1AF25/blob/main/notebooks/notebook-5-llm-api-usage.ipynb), we examined the developer platforms available from major providers of proprietary models (OpenAI, Anthropic, Google). Choose **one** of these providers, and answer the following questions:\n",
    "\n",
    "* Which provider did you choose? List two language models available to developers through their developer platform.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aab5334",
   "metadata": {},
   "source": [
    "> \n",
    "I choose the Open AI.\n",
    "Two language models available:\n",
    "1. GPT-4o (the flagship multimodal model, supporting text, vision, and speech inputs, optimized for cost and latency).\n",
    "2. GPT-4o mini (a faster, cheaper lightweight model designed for real-time tasks, chatbots, and applications where efficiency is critical)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0758948a",
   "metadata": {},
   "source": [
    "* For the two models you listed above, say briefly how they differ in capability and pricing. Your answer can be relatively brief (e.g. 150 words would be fine)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4dc56a",
   "metadata": {},
   "source": [
    "> \n",
    "(1) capability difference\n",
    "1. GPT-4o: it is a more powerful, multimodal “omni” model: it can handle text, vision, and audio inputs (e.g. images, voice) and generate outputs across modalities. It is better suited for applications needing rich context, reasoning, multimodal understanding, or higher quality.\n",
    "2. GPT-4o mini: it is a lighter, cost-optimized variant. It still supports text and vision modalities, but is more limited in scaling, latency, or depths of reasoning. It trades off some performance in favor of efficiency and lower cost. \n",
    "\n",
    "(2)pricing difference\n",
    "1. GPT-4o: it is priced around $2.50 per 1M input tokens and $10.00 per 1M output tokens. \n",
    "2. GPT-4o mini: it is much cheaper: $0.15 per 1M input tokens and $0.60 per 1M output tokens. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928025ad",
   "metadata": {},
   "source": [
    "# GPT2 Analysis\n",
    "In [Notebook 5](https://github.com/ccs-ucb/CSS1AF25/blob/main/notebooks/notebook-5-llm-api-usage.ipynb), you assessed the capabilities of GPT2 by sending text completion requests to our Huggingface app. \n",
    "\n",
    "Based on your interactions with the models, offer brief answers to the following questions. You are welcome to include code snippets or other material in support of your answers if you wish, but this is not required (a verbal answer is ok, if you e.g. explain how you arrived at your answer through testing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8f35df",
   "metadata": {},
   "source": [
    "* Does GPT2 understand the days of the week?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8057d8",
   "metadata": {},
   "source": [
    "> GPT-2 may appear to know some weekday orderings because these patterns exist in text corpora, but its knowledge is shallow and unreliable—it doesn’t “understand” days of the week in any systematic way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffc20dc",
   "metadata": {},
   "source": [
    "* Can GPT2 count?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf7b8db",
   "metadata": {},
   "source": [
    "> GPT-2 can mimic counting for a few steps, but it cannot reliably count beyond short sequences. Its outputs reflect memorized patterns rather than real numerical reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08638e23",
   "metadata": {},
   "source": [
    "* Any other reflections on GPT2 (or reflections on our method of evaluating it's capabilities)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c1b1d1",
   "metadata": {},
   "source": [
    "> GPT-2 shows that early language models can generate fluent text but struggle with systematic reasoning. It may correctly list days or count small sequences, but it quickly drifts or repeats, reflecting pattern prediction rather than real understanding. Our evaluation with simple prompts was effective for revealing these weaknesses, but also limited in scope: one-off completions highlight flaws without showing areas where GPT-2 is relatively strong, such as style or fluency. A broader testing approach across different domains would provide a more balanced picture of its capabilities and limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960efeaa",
   "metadata": {},
   "source": [
    "# Any additional feedback or reflections?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a004c76e",
   "metadata": {},
   "source": [
    "> No"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdc210b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
